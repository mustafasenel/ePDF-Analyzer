# LLM Model KarÅŸÄ±laÅŸtÄ±rmasÄ±

## Mevcut Modeller

### 1. Qwen3-0.6B (VarsayÄ±lan) âš¡
- **Boyut:** ~600MB
- **RAM:** 1-2GB
- **CPU HÄ±zÄ±:** ~2-3 saniye/Ã§Ä±karÄ±m
- **GPU HÄ±zÄ±:** ~0.5 saniye/Ã§Ä±karÄ±m
- **Kalite:** Orta (basit ÅŸirket adlarÄ± iÃ§in yeterli)
- **Ã–nerilen:** CPU ortamlarÄ± iÃ§in

### 2. Qwen2.5-1.5B (Daha Ä°yi) ğŸ¯
- **Boyut:** ~3GB
- **RAM:** 4-5GB
- **CPU HÄ±zÄ±:** ~5-8 saniye/Ã§Ä±karÄ±m
- **GPU HÄ±zÄ±:** ~1-2 saniye/Ã§Ä±karÄ±m
- **Kalite:** Ä°yi (karmaÅŸÄ±k ÅŸirket adlarÄ± ve yapÄ±landÄ±rÄ±lmÄ±ÅŸ veri iÃ§in)
- **Ã–nerilen:** GPU ortamlarÄ± iÃ§in veya yÃ¼ksek doÄŸruluk gerektiÄŸinde

## Model DeÄŸiÅŸtirme

### YÃ¶ntem 1: Config DosyasÄ±

`config/settings.py` dosyasÄ±nÄ± dÃ¼zenle:

```python
# LLM Settings
LLM_MODEL_NAME: str = "Qwen/Qwen2.5-1.5B"  # 0.6B yerine 1.5B
LLM_MAX_TOKENS: int = 256
LLM_TEMPERATURE: float = 0.1
```

### YÃ¶ntem 2: Environment Variable

`.env` dosyasÄ± oluÅŸtur (veya dÃ¼zenle):

```bash
LLM_MODEL_NAME=Qwen/Qwen2.5-1.5B
```

### YÃ¶ntem 3: Sistem Environment

```bash
export LLM_MODEL_NAME="Qwen/Qwen2.5-1.5B"
python3 run.py
```

## Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Ã–zellik | 0.6B | 1.5B |
|---------|------|------|
| Model indirme sÃ¼resi | ~2 dk | ~5 dk |
| Ä°lk baÅŸlatma | ~5 sn | ~10 sn |
| Ã‡Ä±karÄ±m/sayfa (CPU) | 2-3 sn | 5-8 sn |
| Ã‡Ä±karÄ±m/sayfa (GPU) | 0.5 sn | 1-2 sn |
| Åirket adÄ± doÄŸruluÄŸu | %75-80 | %90-95 |
| Adres doÄŸruluÄŸu | %70-75 | %85-90 |
| RAM kullanÄ±mÄ± | 1-2GB | 4-5GB |

## Tavsiyeler

### 0.6B Kullan EÄŸer:
- âœ… CPU'da Ã§alÄ±ÅŸÄ±yorsan
- âœ… HÄ±z Ã¶nemliyse
- âœ… RAM sÄ±nÄ±rlÄ±ysa (< 4GB)
- âœ… Basit e-faturalar iÅŸliyorsan

### 1.5B Kullan EÄŸer:
- âœ… GPU varsa
- âœ… DoÄŸruluk kritikse
- âœ… RAM yeterliyse (> 4GB)
- âœ… KarmaÅŸÄ±k ÅŸirket adlarÄ± var (Ã§ok uzun, kÄ±saltmalar, vs.)

## Test Etme

Model deÄŸiÅŸikliÄŸinden sonra test et:

```bash
# Servisi yeniden baÅŸlat
python3 run.py

# Log'da gÃ¶receksin:
# ğŸ“¥ Loading LLM model: Qwen/Qwen2.5-1.5B
# (Ä°lk Ã§alÄ±ÅŸtÄ±rmada model indirilecek, ~3GB)
```

## DiÄŸer Modeller

Gelecekte eklenebilir:
- `Qwen2.5-3B` - Daha yÃ¼ksek doÄŸruluk (ama Ã§ok yavaÅŸ)
- `Qwen2.5-7B` - Maksimum doÄŸruluk (GPU gerekli, Ã§ok yavaÅŸ)

Not: 3B+ modeller CPU'da pratik deÄŸil, sadece GPU ile kullanÄ±labilir.

